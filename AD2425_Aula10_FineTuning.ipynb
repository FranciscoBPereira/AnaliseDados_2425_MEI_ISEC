{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
  {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoBPereira/AnaliseDados_2425_MEI_ISEC/blob/main/AD2425_Aula10_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0 - Install and Preprocessing**"
      ],
      "metadata": {
        "id": "FSLHURtEsdDL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ1MYT1qkD1O"
      },
      "outputs": [],
      "source": [
        "#Install libraries to run this notebook.\n",
        "\n",
        "!pip install transformers sentence-transformers accelerate evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ1MYT1qkD1O"
      },
      "outputs": [],
      "source": [
        "#Install libraries to run this notebook.\n",
        "\n",
        "!pip install "datasets>=2.18.0,<3"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A. Dataset Loading and Tokenization**"
      ],
      "metadata": {
        "id": "bnMHv9tRfOxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Rotten Tomatoes dataset: https://huggingface.co/datasets/cornell-movie-review-data/rotten_tomatoes\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Prepare data and splits\n",
        "tomatoes = load_dataset(\"rotten_tomatoes\")\n",
        "train_data, test_data = tomatoes[\"train\"], tomatoes[\"test\"]"
      ],
      "metadata": {
        "id": "CjvAxJ-BlYAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect dataset details\n",
        "\n",
        "tomatoes"
      ],
      "metadata": {
        "id": "PC2njrUMmZ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some reviews\n",
        "\n",
        "for i in range(5):\n",
        "    print(train_data[i])"
      ],
      "metadata": {
        "id": "DfIT5eVcmgJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model selection\n",
        "\n",
        "model_id = \"bert-base-cased\""
      ],
      "metadata": {
        "id": "JrotXtsbfjup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "   \"\"\"Tokenize input data\"\"\"\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# Tokenize train/test data\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "id": "CeIIK2Mefr5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B. ModelA loading**"
      ],
      "metadata": {
        "id": "xmAdbdPqskKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ModelA - This model will just adjust its classification head\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "modelA = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n"
      ],
      "metadata": {
        "id": "SXfDX7UlpDI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print layer names for modelA\n",
        "for name, param in modelA.named_parameters():\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "whGbo8fHpiCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all weights from pretrained BERT module\n",
        "\n",
        "for name, param in modelA.named_parameters():\n",
        "\n",
        "     # Trainable classification head\n",
        "     if name.startswith(\"classifier\"):\n",
        "        param.requires_grad = True\n",
        "\n",
        "      # Freeze everything else\n",
        "     else:\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "dRv2TaiLqLOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can check whether the model was correctly updated\n",
        "\n",
        "for name, param in modelA.named_parameters():\n",
        "     print(f\"Parameter: {name} ----- {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "1-quTOXTqTsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "\n",
        "from transformers import TrainingArguments, DataCollatorWithPadding\n",
        "\n",
        "# Pad to the longest sequence in the batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Training arguments for parameter tuning\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "N0bcuLlXq3B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation metrics\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate F1 score\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    load_f1 = evaluate.load(\"f1\")\n",
        "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    return {\"f1\": f1}"
      ],
      "metadata": {
        "id": "XKM74HU3q9lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C. Classification Head Training**"
      ],
      "metadata": {
        "id": "IntUc1o3hLvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Trainer which executes the training process\n",
        "trainerA = Trainer(\n",
        "   model=modelA,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "trainerA.train()"
      ],
      "metadata": {
        "id": "xUbnac-RqhjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D. ModelA Evaluation**"
      ],
      "metadata": {
        "id": "qjDIPEZxhUJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainerA.evaluate()\n"
      ],
      "metadata": {
        "id": "vYetfBM8sEuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E. ModelB Loading**"
      ],
      "metadata": {
        "id": "a6Yp8o0vsRDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ModelB - We will perform fine-tuning with this model\n",
        "\n",
        "modelB = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n"
      ],
      "metadata": {
        "id": "SNtPaBuGsYRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can check that all the weights in this model will be adjusted\n",
        "\n",
        "for name, param in modelB.named_parameters():\n",
        "     print(f\"Parameter: {name} ----- {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "ehMFy2HOuSr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F. ModelB Fine-tuning**"
      ],
      "metadata": {
        "id": "GIO8MgG0h7b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Trainer which executes the training process\n",
        "trainerB = Trainer(\n",
        "   model=modelB,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainerB.train()"
      ],
      "metadata": {
        "id": "yZgmUx9OuPqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**G. ModelB Evaluation**"
      ],
      "metadata": {
        "id": "P4XbzvUiiBWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainerB.evaluate()"
      ],
      "metadata": {
        "id": "ZNepZ24ftmu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyse results**\n",
        "\n",
        "1. Time to train\n",
        "\n",
        "2. Effectiveness on test set"
      ],
      "metadata": {
        "id": "jndA3CfSiHpg"
      }
    }
  ]
}
