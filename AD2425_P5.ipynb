{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nAoTBKXUeLe"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "print('Python version: ', sys.version_info)\n",
        "print('TF version: ', tf.__version__)\n",
        "print('Keras version: ', keras.__version__)\n",
        "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Fetching and Loading**"
      ],
      "metadata": {
        "id": "XyWEjbZ7_KB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Flowers dataset: https://www.kaggle.com/datasets/imsparsh/flowers-dataset\n",
        "\n",
        "# Create folder flower_photos\n",
        "# Inside this folder there are 5 subfolders, one for each category\n",
        "\n",
        "!curl -O https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
        "\n",
        "!tar -xzvf flower_photos.tgz\n",
        "\n",
        "!rm flower_photos.tgz\n",
        "\n"
      ],
      "metadata": {
        "id": "5M08f0BPWXqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('flower_photos')\n",
        "\n",
        "path = os.getcwd()\n",
        "\n"
      ],
      "metadata": {
        "id": "HKlLyYO4l70T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the total number of images\n",
        "\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(path)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "MoskbJ2WWfMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of the dataset objects\n",
        "# The images in the folders are not divided in train and validation datasets\n",
        "# The following code divides samples into 80% training and 20% validation. No test set is created\n",
        "# Check details from previous class and also here: https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "IMG_SIZE = (180, 180)\n",
        "\n",
        "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(1)\n",
        "val_ds = val_ds.cache().prefetch(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "brHkYy_SWpyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset detailed information\n",
        "\n",
        "print('Nr. of classes: ', len(class_names))\n",
        "print('Classes: ', class_names)\n",
        "\n",
        "# Cardinality\n",
        "print('Cardinalidade Treino: ', train_ds.cardinality().numpy())\n",
        "print('Cardinalidade Validacão: ', val_ds.cardinality().numpy())\n",
        "\n",
        "\n",
        "\n",
        "# Explain the cardinality values"
      ],
      "metadata": {
        "id": "Wi6B_53mWuzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few examples\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy()/255.)\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "mV1GEgwIW3Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.\tCreating the baseline version of the Neural Network using the Keras Functional API**"
      ],
      "metadata": {
        "id": "JJ6nUpCU_n3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of a baseline CNN\n",
        "\n",
        "# It must comply with the following constraints:\n",
        "#   1. Use Keras Functional API\n",
        "#   2. Use only Conv2D, MaxPooling, Dense, Flatten and Rescaling layers\n",
        "#   3. Maximum of 5 million parameters\n",
        "#   4. Without Data Augmentation\n",
        "#   5. Do not forget Input Rescaling\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
        "# https://www.tensorflow.org/guide/keras/sequential_model\n",
        "# https://keras.io/api/layers/\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# FUNCTIONAL API\n",
        "\n",
        "inputs = keras.Input(shape=(180,180,3))\n",
        "\n",
        "a = layers.Rescaling(scale = 1./255)(inputs)\n",
        "\n",
        "\n",
        "  ## Complete the Model\n",
        "\n",
        "\n",
        "outputs =  ## Complete ##\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sh5__FWUXDeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the limit for the maximum number of parameters\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CvUBRk7oXTrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "\n",
        "#  1. Select the loss function suitable for this situation\n",
        "#  2. Adopt ADAM optimizer, with default parameterization\n",
        "#  3. Select accuracy metric to evaluate the model\n",
        "\n",
        "L = ## Complete ##\n",
        "\n",
        "model.compile(loss=L, optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "0vl-jCe5XZWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 20 epochs\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=20\n",
        ")"
      ],
      "metadata": {
        "id": "0nUxWwCyXpqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize results (both accuracy and loss)\n",
        "\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
      ],
      "metadata": {
        "id": "UUOMrV8pYAhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "1. Analyze results. By looking at each one of the charts, what do you think is happening?\n",
        "\n",
        "2. Suggest possible strategies to enhance results.\n"
      ],
      "metadata": {
        "id": "xrAqPAPS52rK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tFighting Overfitting: Data Augmentation**"
      ],
      "metadata": {
        "id": "zgms4ZpEAltb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Overview on Data Augmentation:\n",
        "# https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "\n",
        "# Model DA1 relies on Keras preprocessing layers to perform Data Augmentation\n",
        "# https://keras.io/api/layers/preprocessing_layers/image_augmentation/\n",
        "\n",
        "# The data augmentation module is created using the Sequential API\n",
        "\n",
        "data_augmentation1 = keras.Sequential([\n",
        "    layers.RandomFlip(mode='horizontal'),\n",
        "    layers.RandomRotation(factor=0.5),\n",
        "])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v-S9UHq7YEDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize examples of augmented images\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    augmented_images = data_augmentation1(images)\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy()/255.)\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Mj7pWf-HZafW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model DA1 with data augmentation\n",
        "\n",
        "# Keep the previous model and just add the data augmentation layers\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# FUNCTIONAL API\n",
        "\n",
        "inputs = keras.Input(shape=(180,180,3))\n",
        "\n",
        "  ## Complete the model ##\n",
        "\n",
        "model_DA1 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r_x-AFDIEd_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train Model 2\n",
        "\n",
        "L = ## Complete ##\n",
        "\n",
        "model_DA1.compile(loss=L, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "history = model_DA1.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=20\n",
        ")"
      ],
      "metadata": {
        "id": "1XwK8C_GEufp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize results (both accuracy and loss)\n",
        "\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
      ],
      "metadata": {
        "id": "dnNyDTkYDvbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "1. How do you analyze results? Are they similar to those obtained by the previous model?\n"
      ],
      "metadata": {
        "id": "WkpruFAxFLBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new data augmentation module - Model DA2\n",
        "\n",
        "# It should comprise 3 or more pre-processing layers, where, at least, two of them,\n",
        "# must be different from the ones already used\n",
        "\n",
        "# Add the pre-processing module to the beggining of the NN\n",
        "# Compile and train the modified CNN and analyze results\n",
        "\n",
        "# Constraint: 5 million trainable parameters\n",
        "\n",
        "# You can use additional strategies to fight overfitting\n",
        "\n",
        "\n",
        "# CODE GOES HERE - MODEL DA2\n",
        "\n"
      ],
      "metadata": {
        "id": "FTg7TQkgEGFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}