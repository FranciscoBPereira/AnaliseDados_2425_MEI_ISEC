{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoBPereira/AnaliseDados_2425_MEI_ISEC/blob/main/AD2425_P4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVoIRYXrYNGg"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "print('Python version: ', sys.version_info)\n",
        "print('TF version: ', tf.__version__)\n",
        "print('Keras version: ', keras.__version__)\n",
        "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Fetching and Loading**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p1uLQGMmLBR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Dataset and create a directory PetImages with two folders: Cat and Dog\n",
        "# Each of the folders contains images from one class\n",
        "\n",
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
        "\n",
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "\n",
        "!rm kagglecatsanddogs_5340.zip"
      ],
      "metadata": {
        "id": "kTMEkIlh1mn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some images are corrupted, so they have to be removed\n",
        "\n",
        "num_skipped = 0\n",
        "for folder_name in (\"Cat\", \"Dog\"):\n",
        "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = b\"JFIF\" in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "\n",
        "print(f\"Deleted {num_skipped} images.\")"
      ],
      "metadata": {
        "id": "5h3i4kzV2Dd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets for training and validation\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "# https://www.tensorflow.org/guide/data\n",
        "\n",
        "# The method image_dataset_from_directory() creates Dataset objects from images located in a specified directory\n",
        "# https://keras.io/api/data_loading/image/\n",
        "\n",
        "# Parameters subset and validation_split enable the creation of two datasets (Train: 80%; Validation: 20%)\n",
        "# This method may shuffle images, adjust size and define the batch size\n",
        "# This way the dataset is (almost) ready to be processed by the neural network\n",
        "\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(1)\n",
        "val_ds = val_ds.cache().prefetch(1)\n"
      ],
      "metadata": {
        "id": "MtYbT-r32NwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the created datasets\n",
        "\n",
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break\n",
        "\n",
        "print('Class Names: ', class_names)"
      ],
      "metadata": {
        "id": "XU2Mo6WDmXGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets are very important objects and they are associated with a large set of methods\n",
        "# https://www.tensorflow.org/guide/data\n",
        "\n",
        "for m in dir(tf.data.Dataset):\n",
        "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
        "        func = getattr(tf.data.Dataset, m)\n",
        "        if hasattr(func, \"__doc__\"):\n",
        "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
      ],
      "metadata": {
        "id": "L1eG_2S5r3Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few examples\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy()/255.0) # the image from the dataset is transformed into a numpy array\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "xwLmSbjupp--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Creating and Training a Feed-forward Fully Connected Neural Network**"
      ],
      "metadata": {
        "id": "WHydKLTQLScu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "WHZ6FyvC57jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model_FF - FEED-FORWARD NN\n",
        "\n",
        "# Create a feed-forward NN with Keras Sequential API: https://keras.io/api/models/\n",
        "\n",
        "# Complete with the following architecture\n",
        "# 2 hidden layers with 50 neurons each, He weight initialization and ReLU activation function\n",
        "# Last hidden layer must be suitable for a classification problem with 2 classes\n",
        "\n",
        "model_FF = keras.models.Sequential([\n",
        "    layers.InputLayer(shape=(128,128,3)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Rescaling(1./255),\n",
        "\n",
        "    ### COMPLETE ###\n",
        "])"
      ],
      "metadata": {
        "id": "6nA7P4Lm596t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "\n",
        "model_FF.summary()"
      ],
      "metadata": {
        "id": "a2faH77Q9UyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "# Define the loss function (https://keras.io/api/losses/)\n",
        "\n",
        "loss_FF = ### COMPLETE ###\n",
        "\n",
        "model_FF.compile(loss=loss_FF,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "iEbBZxXpCPRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 30 epochs\n",
        "\n",
        "history = model_FF.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "nTbr2Q2ACkoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vF_3tSLPDgTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Present**\n",
        "\n",
        "\n",
        "1.   The last layer selected for your network\n",
        "2.   The selected loss function\n",
        "3.   A brief analysis of results\n"
      ],
      "metadata": {
        "id": "nzoRoJCPvvRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tCreating a Simple CNN**"
      ],
      "metadata": {
        "id": "o6GZ5PKYLaJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_CNN - Convolutional Neural Network\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "73FwnaDDvswM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple CNN\n",
        "\n",
        "# Add the final classification layer to the model\n",
        "\n",
        "model_CNN = keras.models.Sequential([\n",
        "    layers.InputLayer(shape=(128,128,3)),\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, activation='relu',padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu',padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "\n",
        "    ### COMPLETE ###\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "Fcn3akHcv3RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.summary()"
      ],
      "metadata": {
        "id": "sO7NvcgMwo0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1.   How many weights has each kernel/filter of the second convolutional layer?\n",
        "2.   How many feature maps are generated by the last convolutional layer?\n",
        "3.   What is the dimension of each one of these feature maps?"
      ],
      "metadata": {
        "id": "D5AZcAuU-xJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "# Define the loss function\n",
        "\n",
        "lossCNN = ### COMPLETE ###\n",
        "\n",
        "model_CNN.compile(loss= lossCNN,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_CNN.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "sG8NGAD5wx2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the evolution of the accuracy metrics\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_p98AgUdxOtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "How do you analyse the results obtained by this CNN?"
      ],
      "metadata": {
        "id": "QSdBfFwUP8F0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Test the CNN with unseen images of your own pets**\n",
        "\n",
        "1. Upload a jpg image to the working directory\n",
        "2. Specify the name of the image\n",
        "3. Apply the CNN and confirm the prediction"
      ],
      "metadata": {
        "id": "pMKXTURzD6fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Image_Name = '' #@param {type:\"string\"}\n",
        "\n",
        "img = keras.utils.load_img(Image_Name, target_size=image_size)\n",
        "plt.imshow(img)\n",
        "\n",
        "img_array = keras.utils.img_to_array(img)\n",
        "img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "predictions = model_CNN.predict(img_array)\n",
        "score = float(keras.ops.sigmoid(predictions[0][0]))\n",
        "print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
      ],
      "metadata": {
        "id": "xIoFEIdX9DYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.\tImplement and Test Modifications in the CNN**"
      ],
      "metadata": {
        "id": "uNsi6G9dLmZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Design and implement one change in the CNN and repeat the training process,\n",
        "# seeking for an architecture that performs more effectively.\n",
        "\n",
        "# Among other possibilities, you might consider one of the following points:\n",
        "#  1. Change the CNN architecture, adding, deleting, or changing the parameterization of convolutional, maxpooling or dense layers.\n",
        "#  2. Add Batch Normalization and/or Dropout layers.\n",
        "#  3. Add a callback to implement Early Stopping.\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Create a new model called model_CNN2\n",
        "\n",
        "\n",
        "###  CODE GOES HERE   ####\n",
        "\n"
      ],
      "metadata": {
        "id": "U60GDXegxdwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
