{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoBPereira/AnaliseDados_2425_MEI_ISEC/blob/main/AD2425_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JuSbzdc8UYX"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "print('Python version: ', sys.version_info)\n",
        "print('TF version: ', tf.__version__)\n",
        "print('Keras version: ', keras.__version__)\n",
        "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Obtaining the Dataset**\n",
        "\n",
        "**2. Splitting the Dataset into 3 Sets (Train, Test, Validation)**"
      ],
      "metadata": {
        "id": "aISIbs8G3QML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load CIFAR100 dataset from keras datasets:\n",
        "# https://keras.io/api/datasets/cifar100/\n",
        "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "# The load_data() method creates train and test sets. The parameter label_mode specifies the category labels: 'fine' or 'coarse'\n",
        "# In this class we will adopt the coarse classification, corresponding to 20 categories\n",
        "\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "(train_images_full, train_labels_full), (test_images, test_labels) = cifar100.load_data(label_mode = 'coarse')\n",
        "\n",
        "train_labels_full = train_labels_full.squeeze()\n",
        "test_labels = test_labels.squeeze()\n",
        "\n",
        "# We further divide the original train datasets into train and validation datasets\n",
        "train_images = train_images_full[5000:]\n",
        "valid_images = train_images_full[:5000]\n",
        "\n",
        "train_labels = train_labels_full[5000:]\n",
        "valid_labels = train_labels_full[:5000]\n"
      ],
      "metadata": {
        "id": "QC1ftALm_dHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Complete this section\n",
        "# Confirm the dimensions of all tensors previously created\n",
        "\n",
        "# PLACE CODE HERE\n",
        "\n"
      ],
      "metadata": {
        "id": "5fU5y4rh_p8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. What is the shape of the tensors? These dimensions correspond to what?\n",
        "\n",
        "2. How many elements does each of these sets have?\n",
        "\n",
        "3. Why do we need three sets?"
      ],
      "metadata": {
        "id": "K3lYrWjw_225"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Visualizing Some Examples**"
      ],
      "metadata": {
        "id": "bkbCj-Fx3oYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few examples\n",
        "# Check here for the identification of the classes: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "n_rows = 6\n",
        "n_cols = 10\n",
        "\n",
        "# Change the value of start to visualize different examples\n",
        "start = 0\n",
        "\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(train_images[index + start])\n",
        "        plt.axis('off')\n",
        "        plt.title(train_labels[index + start], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bo49AV1nAU-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Creating a Simple Feed-Forward NN**"
      ],
      "metadata": {
        "id": "he3NBgyd33ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "EbIvQ4PjBcNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a feed-forward NN with Keras Sequential API: https://keras.io/api/models/\n",
        "\n",
        "# The base architecture should similar to the one used in the previous class\n",
        "# 1. The Input layer specifies the dimensions of the input images\n",
        "# 2. One hidden layer with 512 nodes, all with the Sigmoid activation function\n",
        "# 3. A final layer with the SoftMax activation function\n",
        "# Complete the missing details:\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=[ ## COMPLETE ##]),\n",
        "    layers.Flatten(),\n",
        "    # COMPLETE\n",
        "    # COMPLETE\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "DTHggPBEBdfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Question:**\n",
        "\n",
        "Explain all the details of the NN that was just created:\n",
        "1. Number of input nodes\n",
        "2. Number of output nodes\n",
        "3. Number of hidden layers and nodes per hidden layer\n",
        "4. Selection of activation functions\n"
      ],
      "metadata": {
        "id": "29wA91ilB58N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Present a summary of the network architecture\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "T9yUOxPDBy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer detailed analysis\n",
        "\n",
        "hidden1 = model.layers[1]\n",
        "weights, biases = hidden1.get_weights()\n",
        "\n",
        "print('Layer ', hidden1.name)\n",
        "print('Weights with shape ', weights.shape, ' :\\n', weights)\n",
        "print('Biases with shape ', biases.shape, ' :\\n', biases)\n"
      ],
      "metadata": {
        "id": "msfPQM2YCQnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "1. How many weights has the NN?\n",
        "\n",
        "2. How many weights has the layer that was selected for detailed inspection?\n",
        "\n",
        "3. How were these weights initialized?\n",
        "\n"
      ],
      "metadata": {
        "id": "ni7NBG9aCadR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Model Compilation**"
      ],
      "metadata": {
        "id": "OcwKcliB4IZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation: https://keras.io/api/models/model_training_apis/\n",
        "# Three components have to be defined:\n",
        "# 1. the Optimizer to be used in training (Select SGD with default learning rate)\n",
        "# 2. The loss function (Select cross entropy for multiple classes)\n",
        "# 3. The evaluation metric\n",
        "\n",
        "L = #COMPLETE with selected loss function#\n",
        "\n",
        "Opt = #COMPLETE with selected Optimizer#\n",
        "\n",
        "model.compile(loss = L,\n",
        "              optimizer= Opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "sROoIWQdCqZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Model Training**"
      ],
      "metadata": {
        "id": "lKDfENtA4Tb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "# Hyper-parameters: batch size and epochs\n",
        "# Validation datasets can also be provided\n",
        "\n",
        "# It returns a history object.\n",
        "# Its History.history attribute is a record of training loss values and metrics values at successive epochs,\n",
        "# as well as validation loss values and validation metrics values (if applicable).\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=20,\n",
        "                    validation_data=(valid_images, valid_labels))\n",
        "\n"
      ],
      "metadata": {
        "id": "TKzCp-bECuuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()\n"
      ],
      "metadata": {
        "id": "Ns8sVM6rC8NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the evolution of the accuracy metrics\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hzME4ag3EQke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Model Evaluation**"
      ],
      "metadata": {
        "id": "44Mx8dv648Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation the generalization ability of the model\n",
        "# The test set will be used in this step\n",
        "# Classification of a set of examples can be performed using the evaluate() method:  https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "fVr86_57ETsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. How do you analyze these results?\n",
        "\n",
        "2. What is the difference between the validation and test datasets?\n",
        "\n"
      ],
      "metadata": {
        "id": "rKrm8lBiEk_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Model Saving**"
      ],
      "metadata": {
        "id": "HQQWbZYB5Jwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model. All models details (architecture, configuration, weights) can be saved to disk.\n",
        "# The method save creates a folder with all the information\n",
        "\n",
        "model.save(\"Modelo_Aula2.keras\")\n",
        "\n",
        "# The model can be later retrieved with the method load_model()\n"
      ],
      "metadata": {
        "id": "g8nTAvdXExks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model to png and save it to a file\n",
        "\n",
        "dot_img_file = 'model1.png'\n",
        "keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_layer_activations=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "HUOm7kfIGrzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10 Changes in the Architecture of the Neural Network**\n",
        "\n",
        "The performance of the neural network is poor. It is mandatory to perform changes, aiming at improving its performance. There are several possibilities that can be tested:\n",
        "\n",
        "\n",
        "\n",
        "1.   Normalize the inputs. Try normalizing the inputs (together with a conversion to real values) and check if the performance changes.\n",
        "\n",
        "2.   The proposed neural network may not be the most suitable for this problem. Change its architecture (number of layers / number of neurons per layer / activation functions) and document how performance changes. The following constraints apply:\n",
        "  *    The Keras Sequential API must be used\n",
        "  *    Only Flatten and Dense layers can be used\n",
        "  *    Activation functions: Sigmoid, Tanh, SoftMax\n",
        "  *    Budget: 3 million weights\n",
        "\n",
        "Perform some tests, document how results change and present a simple analysis of the outcome.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dlH7govfHQH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code goes here\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "Model_2 = keras.Sequential([\n",
        "\n",
        "    # Complete\n",
        "])\n",
        "\n",
        "# Compile\n",
        "\n",
        "# Train\n",
        "\n",
        "# Evaluate\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vSPaajCZHHws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
